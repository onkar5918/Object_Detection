{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"image1.jpeg\")\n",
    "image = cv2.resize(image,(800,800))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,_ = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the neural network\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",'yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open('coco.names','r') as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image,1/255,(416,416),(0,0,0),swapRB=True,crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in blob:\n",
    "    for n, img in enumerate(each):\n",
    "        cv2.imshow(str(n),img)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "outputLayerNames = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(outputLayerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.0420658 , 0.04935352, 0.47844043, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.04183805, 0.03146551, 0.3179572 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.04990423, 0.03824469, 0.7919381 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.9592936 , 0.9544945 , 0.44492567, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9669001 , 0.96307755, 0.30746004, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9671124 , 0.9638399 , 0.8108865 , ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), array([[0.02958412, 0.02393023, 0.04992761, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.02240303, 0.02390786, 0.32753637, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.02205037, 0.01756134, 0.07928602, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.9694878 , 0.9724175 , 0.06430112, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9761178 , 0.9715097 , 0.19180141, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9753768 , 0.9837122 , 0.08112264, ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), array([[0.00839076, 0.00928666, 0.01147314, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01002112, 0.01351422, 0.02132236, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.00997088, 0.01141973, 0.1428416 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.9884895 , 0.9890731 , 0.01912636, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9893761 , 0.98724264, 0.02057526, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.98761654, 0.99036   , 0.12794639, ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(layerOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431, 72, 173, 403], [229, 92, 188, 514], [535, 73, 208, 699], [28, 206, 252, 514], [357, 262, 286, 504], [285, 550, 200, 186], [2, 532, 94, 209], [297, 538, 157, 200], [720, 501, 78, 257]]\n",
      "[0.9173274636268616, 0.9921201467514038, 0.998635470867157, 0.9987161755561829, 0.9882053136825562, 0.9983173608779907, 0.9279079437255859, 0.6637046933174133, 0.7286281585693359]\n",
      "[3 2 5 1 4 6 0 8]\n"
     ]
    }
   ],
   "source": [
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for each in layerOutputs:\n",
    "    for detection in each:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            x = int(center_x - (w/2))\n",
    "            y = int(center_y - (h/2))\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "print(boxes)\n",
    "print(confidences)\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.4)\n",
    "print(indexes.flatten())\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0,255,size = (len(boxes),3))\n",
    "\n",
    "for i in indexes.flatten():\n",
    "    x,y,w,h = boxes[i]\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i],2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),color,2)\n",
    "    cv2.putText(image,label+\" \" + confidence, (x,y+20),font,2,(255,255,255),)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
